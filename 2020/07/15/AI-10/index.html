<!DOCTYPE html><html lang="zh-TW" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>風格轉移 | Zrn-Note</title><meta name="description" content="神經的風格轉移深度學習以另一幅圖像的風格來構成一幅圖像（是否希望您能像畢加索或梵高一樣繪畫？）。這被稱為“神經風格轉換”，該技術在《藝術風格的神經算法》（Gatys等人）中有所概述。神經樣式轉移是一種優化技術，用於拍攝兩個圖像（內容圖像和樣式參考圖像（例如著名畫家的藝術品））並將它們融合在一起，以便輸出圖像看起來像內容圖像，但以樣式參考圖片的樣式“繪製”。這是通過優化輸出圖像以使其與內容圖像的內容"><meta name="keywords" content="AI,深度學習,tensorflow,實作AI,python"><meta name="author" content="Zrn Ye"><meta name="copyright" content="Zrn Ye"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://zrn-coding.github.io/2020/07/15/AI-10/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="風格轉移"><meta property="og:url" content="https://zrn-coding.github.io/2020/07/15/AI-10/"><meta property="og:site_name" content="Zrn-Note"><meta property="og:description" content="神經的風格轉移深度學習以另一幅圖像的風格來構成一幅圖像（是否希望您能像畢加索或梵高一樣繪畫？）。這被稱為“神經風格轉換”，該技術在《藝術風格的神經算法》（Gatys等人）中有所概述。神經樣式轉移是一種優化技術，用於拍攝兩個圖像（內容圖像和樣式參考圖像（例如著名畫家的藝術品））並將它們融合在一起，以便輸出圖像看起來像內容圖像，但以樣式參考圖片的樣式“繪製”。這是通過優化輸出圖像以使其與內容圖像的內容"><meta property="og:image" content="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><meta property="article:published_time" content="2020-07-15T07:08:00.000Z"><meta property="article:modified_time" content="2020-08-19T11:42:27.005Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = '2'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.1.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查詢的內容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  copy: {
    success: '複製成功',
    error: '複製錯誤',
    noSupport: '瀏覽器不支援'
  },
  bookmark: {
    message_prev: '按',
    message_next: '鍵將本頁加入書籤'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"鍵將本頁加入書籤"},"chs_to_cht":"你已切換為繁體","cht_to_chs":"你已切換為簡體","day_to_night":"你已切換為深色模式","night_to_day":"你已切換為淺色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"top-right"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-08-19 19:42:27'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><style type="text/css">#toggle-sidebar {left:100px}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/font-awesome-animation.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><link rel="stylesheet" href="/css/csstest.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/tags.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/plugins.min.css"><meta name="generator" content="Hexo 5.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">載入中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">42</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">標籤</div><div class="length_num">40</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分類</div><div class="length_num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-link faa-horizontal animated"></i><span> 超重要連結</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://zrn-life.github.io"><i class="fa-fw fa fa-home"></i><span> 我的生活</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zrn-code.github.io"><i class="fa-fw fa fa-code faa-horizontal animated"></i><span> 我的程式碼</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 清單</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/club/"><i class="fa-fw fa fa-heart faa-pulse animated"></i><span> 社團資訊</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-address-book faa-tada animated"></i><span> 學習歷程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/presentation/"><i class="fa-fw fa fa-laptop"></i><span> 簡報</span></a></li></ul></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目錄</div><div class="sidebar-toc__progress"><span class="progress-notice">你已經讀了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%B6%93%E7%9A%84%E9%A2%A8%E6%A0%BC%E8%BD%89%E7%A7%BB"><span class="toc-number">1.</span> <span class="toc-text">神經的風格轉移</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B3%87%E6%96%99%E9%A0%90%E8%99%95%E7%90%86"><span class="toc-number">1.1.</span> <span class="toc-text">資料預處理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BC%89%E5%85%A5%E6%89%80%E9%9C%80%E6%A8%A1%E7%B5%84"><span class="toc-number">1.1.1.</span> <span class="toc-text">載入所需模組</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A6%96%E5%8C%96%E7%9A%84%E8%BC%B8%E5%85%A5"><span class="toc-number">1.2.</span> <span class="toc-text">可視化的輸入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E7%BE%A9%E5%9C%96%E7%89%87%E5%8F%8A%E9%A2%A8%E6%A0%BC"><span class="toc-number">1.3.</span> <span class="toc-text">定義圖片及風格</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%96%E7%89%87%E8%88%87%E9%A2%A8%E6%A0%BC%E7%9A%84%E4%B8%AD%E9%96%93%E5%B1%A4"><span class="toc-number">1.3.0.1.</span> <span class="toc-text">圖片與風格的中間層</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E9%80%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">建造模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%B2%E8%A1%8C%E9%A2%A8%E6%A0%BC%E8%A8%88%E7%AE%97"><span class="toc-number">1.5.</span> <span class="toc-text">進行風格計算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%8F%96%E5%9C%96%E7%89%87%E5%8F%8A%E9%A2%A8%E6%A0%BC"><span class="toc-number">1.6.</span> <span class="toc-text">提取圖片及風格</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%8B%E8%A1%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">1.7.</span> <span class="toc-text">運行梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%88%E8%A8%88%E8%AE%8A%E5%8B%95%E7%9A%84loss"><span class="toc-number">1.8.</span> <span class="toc-text">合計變動的loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%8D%E6%AC%A1%E4%BD%BF%E7%94%A8%E6%9C%80%E5%84%AA%E5%8C%96%E6%96%B9%E5%BC%8F"><span class="toc-number">1.9.</span> <span class="toc-text">再次使用最優化方式</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Zrn-Note</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜尋</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-link faa-horizontal animated"></i><span> 超重要連結</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://zrn-life.github.io"><i class="fa-fw fa fa-home"></i><span> 我的生活</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zrn-code.github.io"><i class="fa-fw fa fa-code faa-horizontal animated"></i><span> 我的程式碼</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 清單</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/club/"><i class="fa-fw fa fa-heart faa-pulse animated"></i><span> 社團資訊</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-address-book faa-tada animated"></i><span> 學習歷程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/presentation/"><i class="fa-fw fa fa-laptop"></i><span> 簡報</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">風格轉移</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">發表於</span><time class="post-meta-date-created" datetime="2020-07-15T07:08:00.000Z" title="發表於 2020-07-15 15:08:00">2020-07-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新於</span><time class="post-meta-date-updated" datetime="2020-08-19T11:42:27.005Z" title="更新於 2020-08-19 19:42:27">2020-08-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/%E6%B7%BA%E8%AB%87%E8%88%87%E5%AF%A6%E4%BD%9C/">淺談與實作</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字數總計:</span><span class="word-count">2.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">閲讀時長:</span><span>11分鐘</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">閱讀量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="神經的風格轉移"><a href="#神經的風格轉移" class="headerlink" title="神經的風格轉移"></a>神經的風格轉移</h1><p>深度學習以另一幅圖像的風格來構成一幅圖像（是否希望您能像畢加索或梵高一樣繪畫？）。這被稱為“神經風格轉換”，該技術在《藝術風格的神經算法》（Gatys等人）中有所概述。<br>神經樣式轉移是一種優化技術，用於拍攝兩個圖像（<em>內容</em>圖像和<em>樣式參考</em>圖像（例如著名畫家的藝術品））並將它們融合在一起，以便輸出圖像看起來像內容圖像，但以樣式參考圖片的樣式“繪製”。<br>這是通過優化輸出圖像以使其與內容圖像的內容統計信息和样式參考圖像的樣式統計信息相匹配來實現的。這些統計數據是使用卷積網絡從圖像中提取的。</p>
<h2 id="資料預處理"><a href="#資料預處理" class="headerlink" title="資料預處理"></a>資料預處理</h2><h3 id="載入所需模組"><a href="#載入所需模組" class="headerlink" title="載入所需模組"></a>載入所需模組</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> IPython.display <span class="keyword">as</span> display</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">12</span>,<span class="number">12</span>)</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.grid&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_to_image</span>(<span class="params">tensor</span>):</span></span><br><span class="line">  tensor = tensor*<span class="number">255</span></span><br><span class="line">  tensor = np.array(tensor, dtype=np.uint8)</span><br><span class="line">  <span class="keyword">if</span> np.ndim(tensor)&gt;<span class="number">3</span>:</span><br><span class="line">    <span class="keyword">assert</span> tensor.shape[<span class="number">0</span>] == <span class="number">1</span></span><br><span class="line">    tensor = tensor[<span class="number">0</span>]</span><br><span class="line">  <span class="keyword">return</span> PIL.Image.fromarray(tensor)</span><br></pre></td></tr></table></figure>
<p>載入圖片以及風格</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#載入圖片</span></span><br><span class="line">content_path = tf.keras.utils.get_file(<span class="string">&#x27;YellowLabradorLooking_new.jpg&#x27;</span>, <span class="string">&#x27;https://i.imgur.com/BJsEk2R.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 載入風格</span></span><br><span class="line">style_path = tf.keras.utils.get_file(<span class="string">&#x27;kandinsky5.jpg&#x27;</span>,<span class="string">&#x27;https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="可視化的輸入"><a href="#可視化的輸入" class="headerlink" title="可視化的輸入"></a>可視化的輸入</h2><p>將圖片轉為512像素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_img</span>(<span class="params">path_to_img</span>):</span></span><br><span class="line">  max_dim = <span class="number">512</span></span><br><span class="line">  img = tf.io.read_file(path_to_img)</span><br><span class="line">  img = tf.image.decode_image(img, channels=<span class="number">3</span>)</span><br><span class="line">  img = tf.image.convert_image_dtype(img, tf.float32)</span><br><span class="line"></span><br><span class="line">  shape = tf.cast(tf.shape(img)[:<span class="number">-1</span>], tf.float32)</span><br><span class="line">  long_dim = max(shape)</span><br><span class="line">  scale = max_dim / long_dim</span><br><span class="line"></span><br><span class="line">  new_shape = tf.cast(shape * scale, tf.int32)</span><br><span class="line"></span><br><span class="line">  img = tf.image.resize(img, new_shape)</span><br><span class="line">  img = img[tf.newaxis, :]</span><br><span class="line">  <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>
<p>簡單的檢視圖片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">image, title=None</span>):</span></span><br><span class="line">  <span class="keyword">if</span> len(image.shape) &gt; <span class="number">3</span>:</span><br><span class="line">    image = tf.squeeze(image, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  plt.imshow(image)</span><br><span class="line">  <span class="keyword">if</span> title:</span><br><span class="line">    plt.title(title)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">content_image = load_img(content_path)</span><br><span class="line">style_image = load_img(style_path)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">imshow(content_image, <span class="string">&#x27;Content Image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">imshow(style_image, <span class="string">&#x27;Style Image&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow_hub <span class="keyword">as</span> hub</span><br><span class="line">hub_module = hub.load(<span class="string">&#x27;https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/1&#x27;</span>)</span><br><span class="line">stylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[<span class="number">0</span>]</span><br><span class="line">tensor_to_image(stylized_image)</span><br></pre></td></tr></table></figure>
<h2 id="定義圖片及風格"><a href="#定義圖片及風格" class="headerlink" title="定義圖片及風格"></a>定義圖片及風格</h2><p>使用模型的中間層來獲取圖像的內容和樣式表示。從網絡的輸入層開始，前幾層的激活表示諸如邊緣和紋理之類的低級特徵。當您遍歷網絡時，最後幾層代表更高級別的功能-諸如輪子或眼睛之類的對象部分。在這種情況下，您使用的是VGG19網絡體系結構，即預訓練的圖像分類網絡。這些中間層對於定義圖像中內容和样式的表示是必不可少的。對於輸入圖像，請嘗試在這些中間層匹配相應的樣式和內容目標表示。</p>
<p>加載一個VGG19並在我們的映像上對其進行測試以確保其正確使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = tf.keras.applications.vgg19.preprocess_input(content_image*<span class="number">255</span>)</span><br><span class="line">x = tf.image.resize(x, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">vgg = tf.keras.applications.VGG19(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">prediction_probabilities = vgg(x)</span><br><span class="line">prediction_probabilities.shape</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[<span class="number">0</span>]</span><br><span class="line">[(class_name, prob) <span class="keyword">for</span> (number, class_name, prob) <span class="keyword">in</span> predicted_top_5]</span><br></pre></td></tr></table></figure>
<p>現在加載沒有分類頭的<code>VGG19</code>，並列出層名稱</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vgg = tf.keras.applications.VGG19(include_top=<span class="literal">False</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg.layers:</span><br><span class="line">  print(layer.name)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">content_layers = [<span class="string">&#x27;block5_conv2&#x27;</span>] </span><br><span class="line"></span><br><span class="line">style_layers = [<span class="string">&#x27;block1_conv1&#x27;</span>,<span class="string">&#x27;block2_conv1&#x27;</span>, <span class="string">&#x27;block3_conv1&#x27;</span>, </span><br><span class="line">                          <span class="string">&#x27;block4_conv1&#x27;</span>,  <span class="string">&#x27;block5_conv1&#x27;</span>]</span><br><span class="line">num_content_layers = len(content_layers)</span><br><span class="line">num_style_layers = len(style_layers)</span><br></pre></td></tr></table></figure>

<h4 id="圖片與風格的中間層"><a href="#圖片與風格的中間層" class="headerlink" title="圖片與風格的中間層"></a>圖片與風格的中間層</h4><p>那麼，為什麼在我們的預訓練圖像分類網絡中這些中間輸出可以讓我們定義樣式和內容表示形式？</p>
<p>在較高級別上，為了使網絡執行圖像分類（已訓練該網絡進行此操作），它必須了解圖像。 這就要求將原始圖像作為輸入像素，並建立一個內部表示形式，以將原始圖像像素轉換為對圖像中存在的特徵的複雜理解。</p>
<p>這也是卷積神經網絡能夠很好地泛化的原因：它們能夠捕獲不變性並在類別（例如貓與狗）中定義與背景噪聲和其他煩擾無關的特徵。 因此，在原始圖像被饋送到模型和輸出分類標籤之間的某處，模型充當了複雜的特徵提取器。 通過訪問模型的中間層，您可以描述輸入圖像的內容和樣式。</p>
<h2 id="建造模型"><a href="#建造模型" class="headerlink" title="建造模型"></a>建造模型</h2><p>tf.keras.applications中的網絡經過設計，因此您可以使用Keras功能API輕鬆提取中間層值。<br>要使用功能性API定義模型，請指定輸入和輸出：<br>模型=模型（輸入，輸出）<br>下面的函數構建一個VGG19模型，該模型返回中間層輸出的列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_layers</span>(<span class="params">layer_names</span>):</span></span><br><span class="line">  vgg = tf.keras.applications.VGG19(include_top=<span class="literal">False</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">  vgg.trainable = <span class="literal">False</span></span><br><span class="line">  outputs = [vgg.get_layer(name).output <span class="keyword">for</span> name <span class="keyword">in</span> layer_names]</span><br><span class="line">  model = tf.keras.Model([vgg.input], outputs)</span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="進行風格計算"><a href="#進行風格計算" class="headerlink" title="進行風格計算"></a>進行風格計算</h2><p>圖像的內容由中間特徵圖的值表示。</p>
<p>事實證明，圖像的樣式可以通過不同特徵圖中的均值和相關性來描述。 通過在每個位置取特徵向量與其自身的外積，並對所有位置的該外積求平均值，計算出包含此信息的Gram矩陣。 可以針對特定層計算此Gram矩陣，如下所示：<br>$$G^l_{cd} = \frac{\sum_{ij} F^l_{ijc}(x)F^l_{ijd}(x)}{IJ}$$</p>
<p>這可以使用<code>tf.linalg.einsum</code>函數簡潔地實現：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#使用tf.linalg.einsum函數</span><br><span class="line">def gram_matrix(input_tensor):</span><br><span class="line">  result &#x3D; tf.linalg.einsum(&#39;bijc,bijd-&gt;bcd&#39;, input_tensor, input_tensor)</span><br><span class="line">  input_shape &#x3D; tf.shape(input_tensor)</span><br><span class="line">  num_locations &#x3D; tf.cast(input_shape[1]*input_shape[2], tf.float32)</span><br><span class="line">  return result&#x2F;(num_locations)</span><br></pre></td></tr></table></figure>
<h2 id="提取圖片及風格"><a href="#提取圖片及風格" class="headerlink" title="提取圖片及風格"></a>提取圖片及風格</h2><p>建立一個返回風格和圖片張量的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StyleContentModel</span>(<span class="params">tf.keras.models.Model</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, style_layers, content_layers</span>):</span></span><br><span class="line">    super(StyleContentModel, self).__init__()</span><br><span class="line">    self.vgg =  vgg_layers(style_layers + content_layers)</span><br><span class="line">    self.style_layers = style_layers</span><br><span class="line">    self.content_layers = content_layers</span><br><span class="line">    self.num_style_layers = len(style_layers)</span><br><span class="line">    self.vgg.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="string">&quot;Expects float input in [0,1]&quot;</span></span><br><span class="line">    inputs = inputs*<span class="number">255.0</span></span><br><span class="line">    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)</span><br><span class="line">    outputs = self.vgg(preprocessed_input)</span><br><span class="line">    style_outputs, content_outputs = (outputs[:self.num_style_layers], </span><br><span class="line">                                      outputs[self.num_style_layers:])</span><br><span class="line"></span><br><span class="line">    style_outputs = [gram_matrix(style_output)</span><br><span class="line">                     <span class="keyword">for</span> style_output <span class="keyword">in</span> style_outputs]</span><br><span class="line"></span><br><span class="line">    content_dict = &#123;content_name:value </span><br><span class="line">                    <span class="keyword">for</span> content_name, value </span><br><span class="line">                    <span class="keyword">in</span> zip(self.content_layers, content_outputs)&#125;</span><br><span class="line"></span><br><span class="line">    style_dict = &#123;style_name:value</span><br><span class="line">                  <span class="keyword">for</span> style_name, value</span><br><span class="line">                  <span class="keyword">in</span> zip(self.style_layers, style_outputs)&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;content&#x27;</span>:content_dict, <span class="string">&#x27;style&#x27;</span>:style_dict&#125;</span><br></pre></td></tr></table></figure>
<p>當在圖像上調用該模型時，該模型返回<code>style_layers</code>的語法矩陣（風格）和<code>content_layers</code>的內容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">extractor = StyleContentModel(style_layers, content_layers)</span><br><span class="line"></span><br><span class="line">results = extractor(tf.constant(content_image))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Styles:&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> name, output <span class="keyword">in</span> sorted(results[<span class="string">&#x27;style&#x27;</span>].items()):</span><br><span class="line">  print(<span class="string">&quot;  &quot;</span>, name)</span><br><span class="line">  print(<span class="string">&quot;    shape: &quot;</span>, output.numpy().shape)</span><br><span class="line">  print(<span class="string">&quot;    min: &quot;</span>, output.numpy().min())</span><br><span class="line">  print(<span class="string">&quot;    max: &quot;</span>, output.numpy().max())</span><br><span class="line">  print(<span class="string">&quot;    mean: &quot;</span>, output.numpy().mean())</span><br><span class="line">  print()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Contents:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> name, output <span class="keyword">in</span> sorted(results[<span class="string">&#x27;content&#x27;</span>].items()):</span><br><span class="line">  print(<span class="string">&quot;  &quot;</span>, name)</span><br><span class="line">  print(<span class="string">&quot;    shape: &quot;</span>, output.numpy().shape)</span><br><span class="line">  print(<span class="string">&quot;    min: &quot;</span>, output.numpy().min())</span><br><span class="line">  print(<span class="string">&quot;    max: &quot;</span>, output.numpy().max())</span><br><span class="line">  print(<span class="string">&quot;    mean: &quot;</span>, output.numpy().mean())</span><br></pre></td></tr></table></figure>
<h2 id="運行梯度下降"><a href="#運行梯度下降" class="headerlink" title="運行梯度下降"></a>運行梯度下降</h2><p>使用此樣式和內容提取器，您現在可以實現樣式傳輸算法。 為此，請計算圖像輸出相對於每個目標的均方誤差，然後取這些損失的加權總和。</p>
<p>設置樣式和內容目標值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">style_targets = extractor(style_image)[<span class="string">&#x27;style&#x27;</span>]</span><br><span class="line">content_targets = extractor(content_image)[<span class="string">&#x27;content&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>定義一個 <code>tf.Variable</code>以包含要優化的圖像。 為了快速實現，請使用內容圖像對其進行初始化（<code>tf.Variable</code>必須與內容圖像具有相同的形狀）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用 tf.Variable 定義圖像</span></span><br><span class="line">image = tf.Variable(content_image)</span><br></pre></td></tr></table></figure>
<p>由於這是浮動圖像，因此定義一個函數以將像素值保持在0到1之間：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定義一個函數以將像素值保持在0到1之間</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clip_0_1</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">return</span> tf.clip_by_value(image, clip_value_min=<span class="number">0.0</span>, clip_value_max=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>

<p>在此處使用adam做優化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用adam做優化</span></span><br><span class="line">opt = tf.optimizers.Adam(learning_rate=<span class="number">0.02</span>, beta_1=<span class="number">0.99</span>, epsilon=<span class="number">1e-1</span>)</span><br></pre></td></tr></table></figure>
<p>要對此進行優化，請使用兩個損失的加權組合來獲得總損失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用兩個損失的加權組合來獲得總損失：</span></span><br><span class="line">style_weight=<span class="number">1e-2</span></span><br><span class="line">content_weight=<span class="number">1e4</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_content_loss</span>(<span class="params">outputs</span>):</span></span><br><span class="line">    style_outputs = outputs[<span class="string">&#x27;style&#x27;</span>]</span><br><span class="line">    content_outputs = outputs[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**<span class="number">2</span>) </span><br><span class="line">                           <span class="keyword">for</span> name <span class="keyword">in</span> style_outputs.keys()])</span><br><span class="line">    style_loss *= style_weight / num_style_layers</span><br><span class="line"></span><br><span class="line">    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**<span class="number">2</span>) </span><br><span class="line">                             <span class="keyword">for</span> name <span class="keyword">in</span> content_outputs.keys()])</span><br><span class="line">    content_loss *= content_weight / num_content_layers</span><br><span class="line">    loss = style_loss + content_loss</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>使用<code>tf.GradientTape</code>更新圖像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用tf.GradientTape更新圖像</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tf.function()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">image</span>):</span></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    outputs = extractor(image)</span><br><span class="line">    loss = style_content_loss(outputs)</span><br><span class="line"></span><br><span class="line">  grad = tape.gradient(loss, image)</span><br><span class="line">  opt.apply_gradients([(grad, image)])</span><br><span class="line">  image.assign(clip_0_1(image))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">steps_per_epoch = <span class="number">100</span></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(epochs):</span><br><span class="line">  <span class="keyword">for</span> m <span class="keyword">in</span> range(steps_per_epoch):</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">    train_step(image)</span><br><span class="line">    print(<span class="string">&quot;.&quot;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">  display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">  display.display(tensor_to_image(image))</span><br><span class="line">  print(<span class="string">&quot;Train step: &#123;&#125;&quot;</span>.format(step))</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">&quot;Total time: &#123;:.1f&#125;&quot;</span>.format(end-start))</span><br></pre></td></tr></table></figure>
<h2 id="合計變動的loss"><a href="#合計變動的loss" class="headerlink" title="合計變動的loss"></a>合計變動的loss</h2><p>這種基本實現的一個缺點是，它會產生許多高頻偽像。在圖像的高頻分量上使用顯式正則項來減少這些誤差。在樣式轉換中，這通常稱為<strong>總變化損失</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">high_pass_x_y</span>(<span class="params">image</span>):</span></span><br><span class="line">  x_var = image[:,:,<span class="number">1</span>:,:] - image[:,:,:<span class="number">-1</span>,:]</span><br><span class="line">  y_var = image[:,<span class="number">1</span>:,:,:] - image[:,:<span class="number">-1</span>,:,:]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> x_var, y_var</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x_deltas, y_deltas = high_pass_x_y(content_image)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*y_deltas+<span class="number">0.5</span>), <span class="string">&quot;Horizontal Deltas: Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*x_deltas+<span class="number">0.5</span>), <span class="string">&quot;Vertical Deltas: Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">x_deltas, y_deltas = high_pass_x_y(image)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*y_deltas+<span class="number">0.5</span>), <span class="string">&quot;Horizontal Deltas: Styled&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">imshow(clip_0_1(<span class="number">2</span>*x_deltas+<span class="number">0.5</span>), <span class="string">&quot;Vertical Deltas: Styled&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>這顯示了高頻分量如何增加。</p>
<p>而且，該高頻分量基本上是邊緣檢測器。您可以從Sobel邊緣檢測器獲得類似的輸出，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize&#x3D;(14,10))</span><br><span class="line"></span><br><span class="line">sobel &#x3D; tf.image.sobel_edges(content_image)</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">imshow(clip_0_1(sobel[...,0]&#x2F;4+0.5), &quot;Horizontal Sobel-edges&quot;)</span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">imshow(clip_0_1(sobel[...,1]&#x2F;4+0.5), &quot;Vertical Sobel-edges&quot;)</span><br></pre></td></tr></table></figure>
<p>與此相關的正則化損失是值的平方和：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def total_variation_loss(image):</span><br><span class="line">  x_deltas, y_deltas &#x3D; high_pass_x_y(image)</span><br><span class="line">  return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_variation_loss(image).numpy()</span><br></pre></td></tr></table></figure>
<p>那證明了它的作用。 但是無需自己實現，TensorFlow包含一個標準實現：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.image.total_variation(image).numpy()</span><br></pre></td></tr></table></figure>
<h2 id="再次使用最優化方式"><a href="#再次使用最優化方式" class="headerlink" title="再次使用最優化方式"></a>再次使用最優化方式</h2><p>為<code>total_variation_loss</code>選擇一個權重:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_variation_weight&#x3D;30</span><br></pre></td></tr></table></figure>
<p>將<code>train_step</code> 引入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@tf.function()</span><br><span class="line">def train_step(image):</span><br><span class="line">  with tf.GradientTape() as tape:</span><br><span class="line">    outputs &#x3D; extractor(image)</span><br><span class="line">    loss &#x3D; style_content_loss(outputs)</span><br><span class="line">    loss +&#x3D; total_variation_weight*tf.image.total_variation(image)</span><br><span class="line"></span><br><span class="line">  grad &#x3D; tape.gradient(loss, image)</span><br><span class="line">  opt.apply_gradients([(grad, image)])</span><br><span class="line">  image.assign(clip_0_1(image))</span><br></pre></td></tr></table></figure>
<p>重新初始化優化變量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image &#x3D; tf.Variable(content_image)</span><br></pre></td></tr></table></figure>
<p>並運行優化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">start &#x3D; time.time()</span><br><span class="line"></span><br><span class="line">epochs &#x3D; 10</span><br><span class="line">steps_per_epoch &#x3D; 100</span><br><span class="line"></span><br><span class="line">step &#x3D; 0</span><br><span class="line">for n in range(epochs):</span><br><span class="line">  for m in range(steps_per_epoch):</span><br><span class="line">    step +&#x3D; 1</span><br><span class="line">    train_step(image)</span><br><span class="line">    print(&quot;.&quot;, end&#x3D;&#39;&#39;)</span><br><span class="line">  display.clear_output(wait&#x3D;True)</span><br><span class="line">  display.display(tensor_to_image(image))</span><br><span class="line">  print(&quot;Train step: &#123;&#125;&quot;.format(step))</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(&quot;Total time: &#123;:.1f&#125;&quot;.format(end-start))</span><br></pre></td></tr></table></figure>

<p>最後，儲存訓練結果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">file_name &#x3D; &#39;stylized-image.png&#39;</span><br><span class="line">tensor_to_image(image).save(file_name)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">  from google.colab import files</span><br><span class="line">except ImportError:</span><br><span class="line">   pass</span><br><span class="line">else:</span><br><span class="line">  files.download(file_name)</span><br></pre></td></tr></table></figure></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Zrn Ye</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章連結: </span><span class="post-copyright-info"><a href="https://zrn-coding.github.io/2020/07/15/AI-10/">https://zrn-coding.github.io/2020/07/15/AI-10/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版權聲明: </span><span class="post-copyright-info">本部落格所有文章除特別聲明外，均採用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 許可協議。轉載請註明來自 <a href="https://zrn-coding.github.io" target="_blank">Zrn-Note</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/">深度學習</a><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a><a class="post-meta__tags" href="/tags/%E5%AF%A6%E4%BD%9CAI/">實作AI</a><a class="post-meta__tags" href="/tags/python/">python</a></div><div class="post_share"><div class="social-share" data-image="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg" data-sites="facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/08/19/vector/"><img class="prev-cover" data-lazy-src="https://images.squarespace-cdn.com/content/v1/5475f6eae4b0821160f6ac3e/1552685579264-XJODR3H54QVZSCCH2H5B/ke17ZwdGBToddI8pDm48kH12H_EdUeZY-Tvv_svcNx9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI4AEFf-Jlj0yHs2ru3Hd-GQga4EnrFO4bxXsJo1lTp14KMshLAGzx4R3EDFOm1kBS/lifelong+learning" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">vector的使用(新)</div></div></a></div><div class="next-post pull-right"><a href="/2020/07/12/string/"><img class="next-cover" data-lazy-src="https://images.squarespace-cdn.com/content/v1/5475f6eae4b0821160f6ac3e/1552685579264-XJODR3H54QVZSCCH2H5B/ke17ZwdGBToddI8pDm48kH12H_EdUeZY-Tvv_svcNx9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI4AEFf-Jlj0yHs2ru3Hd-GQga4EnrFO4bxXsJo1lTp14KMshLAGzx4R3EDFOm1kBS/lifelong+learning" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">字串處理</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相關推薦</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/06/12/AI-9/" title="圖片分割"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-12</div><div class="relatedPosts_title">圖片分割</div></div></a></div><div class="relatedPosts_item"><a href="/2020/05/21/AI-8/" title="LSTM"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-21</div><div class="relatedPosts_title">LSTM</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/30/AI-7/" title="IMDb情緒分析"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-30</div><div class="relatedPosts_title">IMDb情緒分析</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/23/AI-6/" title="CNN辨識物體"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-23</div><div class="relatedPosts_title">CNN辨識物體</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/16/AI-5/" title="CNN手寫辨識"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-16</div><div class="relatedPosts_title">CNN手寫辨識</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/09/AI-4/" title="Keras MLP辨識手寫數字"><img class="relatedPosts_cover" data-lazy-src="https://www.ceotodaymagazine.com/CEO-Today/wp-content/uploads/2018/04/28-Brands-That-Use-AI-to-Enhance-Marketing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-09</div><div class="relatedPosts_title">Keras MLP辨識手寫數字</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Zrn Ye</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主題 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="閱讀模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字型"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="縮小字型"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="簡繁轉換">簡</button><button id="darkmode" type="button" title="淺色和深色模式轉換"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="設定"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目錄"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到頂部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜尋</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜尋文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  var script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    $.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js', function () {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      true && mermaid.init()
    })
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="aplayer no-destroy" data-id="3020052469" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="false" muted></div><script src="https://unpkg.com/xiaokang-style/butterfly/js/xkTool.js"></script><script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/js/pool.min.js"></script><script src="/js/jstest.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script src="/js/third-party/ClickShowText.js" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  'meta[name=description]',
  '#config_change',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if () {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

const pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
})

document.addEventListener('pjax:complete', function () {
  refreshFn()

  $('script[data-pjax]').each(function () {
    $(this).parent().append($(this).remove())
  })

  GLOBAL_CONFIG.islazyload && lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  if (typeof gtag === 'function') {
    gtag('config', '', {'page_path': window.location.pathname});
  }

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

})

document.addEventListener('pjax:send', function () {
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  $(window).off('scroll')

  //reset readmode
  $('body').hasClass('read-mode') && $('body').removeClass('read-mode')

  //reset font-size
  $('body').css('font-size') !== originFontSize && $('body').css('font-size', parseFloat(originFontSize))
})</script></div></body></html>